extensions:
  health_check:
    endpoint: 0.0.0.0:13133
  http_forwarder:
    ingress:
      endpoint: 0.0.0.0:6060
    egress:
      # TODO: Ensure this is set properly
      endpoint: "https://api.${SPLUNK_REALM}.signalfx.com"
  zpages:
  memory_ballast:
    # In general, the ballast should be set to 1/3 of the collector's memory, the limit
    # should be 90% of the collector's memory.
    # The simplest way to specify the ballast size is set the value of SPLUNK_BALLAST_SIZE_MIB env variable.
    # TODO: Ensure this is set properly
    size_mib: ${SPLUNK_BALLAST_SIZE_MIB}
receivers:
  filelog:
    include:
      - /var/lib/docker/containers/*/*-json.log
    encoding: utf-8
    fingerprint_size: 1kb
    force_flush_period: "0"
    include_file_name: false
    include_file_path: true
    max_concurrent_files: 1024
    max_log_size: 1MiB
    operators:
      - id: parser-docker
        timestamp:
          layout: '%Y-%m-%dT%H:%M:%S.%LZ'
          parse_from: attributes.time
        type: json_parser
      - id: extract_metadata_from_docker_tag
        parse_from: attributes.attrs.tag
        regex: ^(?P<name>[^\|]+)\|(?P<image_name>[^\|]+)\|(?P<id>[^$]+)$
        type: regex_parser
        if: 'attributes?.attrs?.tag != nil'
      - from: attributes.name
        to: resource["com.splunk.sourcetype"]
        type: copy
        if: 'attributes?.name != nil'
      - from: attributes.name
        to: resource["docker.container.name"]
        type: move
        if: 'attributes?.name != nil'
      - from: attributes.image_name
        to: resource["docker.image.name"]
        type: move
        if: 'attributes?.image_name != nil'
      - from: attributes.id
        to: resource["docker.container.id"]
        type: move
        if: 'attributes?.id != nil'
      - from: attributes.stream
        to: resource["log.io.stream"]
        type: move
      - field: attributes.attrs.tag
        type: remove
        if: 'attributes?.attrs?.tag != nil'
      - from: attributes.log
        to: body
        type: move
    poll_interval: 200ms
    start_at: beginning

  hostmetrics:
    collection_interval: 10s
    scrapers:
      cpu:
      disk:
      filesystem:
      memory:
      network:
      # System load average metrics https://en.wikipedia.org/wiki/Load_(computing)
      load:
      # Paging/Swap space utilization and I/O metrics
      paging:
      # Aggregated system process count metrics
      processes:
      # System processes metrics, disabled by default
      # process:
  otlp:
    protocols:
      grpc:
        endpoint: 0.0.0.0:4317
      http:
        endpoint: 0.0.0.0:4318

  sapm:
    endpoint: 0.0.0.0:7276
  signalfx:
    endpoint: 0.0.0.0:9943
  # This section is used to collect OpenTelemetry metrics
  # Even if just a SignalFx APM customer, these metrics are included
  prometheus:
    config:
      scrape_configs:
        - job_name: 'otel-collector'
          scrape_interval: 10s
          static_configs:
            - targets: ['localhost:8888']
              # If you want to use the environment filter
              # In the SignalFx dashboard
              #labels:
              #environment: demo
          metric_relabel_configs:
            - source_labels: [ __name__ ]
              regex: '.*grpc_io.*'
              action: drop
  # Enable Zipkin to support Istio Mixer Adapter
  # https://github.com/signalfx/signalfx-istio-adapter
  zipkin:
    endpoint: 0.0.0.0:9411
  redis:
    endpoint: "valkey-cart:6379"
    username: "valkey"
    collection_interval: 10s

processors:
  batch:
  # Optional: If you have a different environment tag name
  # If this option is enabled it must be added to the pipeline section below
  #attributes/copyfromexistingkey:
  #actions:
  #- key: environment
  #from_attribute: YOUR_EXISTING_TAG_NAME
  #action: upsert
  # Optional: If you want to add an environment tag
  # If this option is enabled it must be added to the pipeline section below
  #attributes/newenvironment:
  #actions:
  #- key: environment
  #value: "YOUR_ENVIRONMENT_NAME"
  #action: insert
  resourcedetection:
    detectors:
      - env
      - system
    timeout: 10s
    override: true

exporters:
  # Traces
  sapm:
    # TODO: Ensure this is set properly
    access_token: "${SPLUNK_ACCESS_TOKEN}"
    # TODO: Ensure this is set properly
    endpoint: "https://ingest.${SPLUNK_REALM}.signalfx.com/v2/trace"
  # Metrics
  signalfx:
    # TODO: Ensure this is set properly
    access_token: "${SPLUNK_ACCESS_TOKEN}"
    # TODO: Ensure this is set properly
    realm: "${SPLUNK_REALM}"
    sync_host_metadata: true
  # Logs (can also be used to send traces)
  splunk_hec:
    token: "${SPLUNK_HEC_TOKEN}"
    endpoint: "${SPLUNK_HEC_URL}/services/collector"
    source: "otel"
    sourcetype: "otel"
    index: "astronomyshop"
    profiling_data_enabled: false
    tls:
      insecure_skip_verify: false

service:
  extensions: [health_check, http_forwarder, zpages]
  #  telemetry:
  #    logs:
  #      level: "debug"

  pipelines:
    traces:
      receivers: [otlp, sapm, zipkin]
      processors: [batch, resourcedetection]
      exporters: [ sapm, signalfx ]
    metrics:
      receivers: [otlp, signalfx, prometheus, hostmetrics]
      processors: [batch, resourcedetection]
      exporters: [signalfx]
    logs:
      receivers: [otlp, signalfx, filelog]
      processors: [batch, resourcedetection]
      exporters: [splunk_hec]
    metrics/additional-receivers:
      exporters:
        - signalfx
      processors:
        - batch
        - resourcedetection
      receivers:
        - redis
